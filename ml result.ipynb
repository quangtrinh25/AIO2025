Total Samples 160
Positive Samples 20
=============OVERSAMPLING===============
Total Samples 280
Positive Samples 140
Fitting encoders on complete dataset...
X_df (280, 1683)
y_df (280,)
gender unique values: ['F', 'M']
ethnicity unique values: ['AMERICAN INDIAN/ALASKA NATIVE', 'ASIAN', 'ASIAN - ASIAN INDIAN', 'ASIAN - SOUTH EAST ASIAN', 'BLACK/AFRICAN', 'BLACK/AFRICAN AMERICAN', 'BLACK/CAPE VERDEAN', 'BLACK/CARIBBEAN ISLAND', 'HISPANIC/LATINO - PUERTO RICAN', 'OTHER', 'UNABLE TO OBTAIN', 'UNKNOWN', 'WHITE', 'WHITE - OTHER EUROPEAN', 'WHITE - RUSSIAN']
insurance unique values: ['0', 'MEDICAID', 'MEDICARE', 'OTHER', 'PRIVATE']
=================== 0 FOLD=====================
train_hids 112
X_df (112, 1683)
y_df (112,)
test_hids 28
X_df (28, 1683)
y_df (28,)
Training shape: (112, 1683), Test shape: (28, 1683)
Training dtypes: {dtype('int64'): 1475, dtype('float64'): 208}
===============MODEL TRAINING===============
Fitting 5 folds for each of 32 candidates, totalling 160 fits
Best params for F1: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}
Best F1 score: 0.9550
Average CV Metrics:
  Accuracy: 0.9470 (+/- 0.0513)
  Precision: 0.9286 (+/- 0.0639)
  Recall: 0.9846 (+/- 0.0308)
  F1: 0.9550 (+/- 0.0436)
  Roc_auc: 0.9685 (+/- 0.0390)
BCE Loss: 0.16
AU-ROC: 1.00
AU-PRC: 1.00
AU-PRC Baaseline: 0.54
Accuracy: 1.00
Precision: 1.00
Recall: 1.00
Specificity: 1.00
NPV: 1.00
ECE: 0.07
MCE: 0.34
Model saved to D:/ICUDATASET/data/output/Xgboost_model.pkl
=================== 1 FOLD=====================
train_hids 112
X_df (112, 1683)
y_df (112,)
test_hids 28
X_df (28, 1683)
y_df (28,)
Training shape: (112, 1683), Test shape: (28, 1683)
Training dtypes: {dtype('int64'): 1475, dtype('float64'): 208}
===============MODEL TRAINING===============
Fitting 5 folds for each of 32 candidates, totalling 160 fits
Best params for F1: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}
Best F1 score: 0.9680
Average CV Metrics:
  Accuracy: 0.9648 (+/- 0.0508)
  Precision: 0.9679 (+/- 0.0393)
  Recall: 0.9692 (+/- 0.0615)
  F1: 0.9680 (+/- 0.0466)
  Roc_auc: 0.9732 (+/- 0.0365)
BCE Loss: 0.53
AU-ROC: 0.95
AU-PRC: 0.93
AU-PRC Baaseline: 0.54
Accuracy: 0.96
Precision: 0.94
Recall: 1.00
Specificity: 0.92
NPV: 1.00
ECE: 0.11
MCE: 0.45
Model saved to D:/ICUDATASET/data/output/Xgboost_model.pkl
=================== 2 FOLD=====================
train_hids 112
X_df (112, 1683)
y_df (112,)
test_hids 28
X_df (28, 1683)
y_df (28,)
Training shape: (112, 1683), Test shape: (28, 1683)
Training dtypes: {dtype('int64'): 1475, dtype('float64'): 208}
===============MODEL TRAINING===============
Fitting 5 folds for each of 32 candidates, totalling 160 fits
Best params for F1: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}
Best F1 score: 0.9396
Average CV Metrics:
  Accuracy: 0.9375 (+/- 0.0782)
  Precision: 0.9492 (+/- 0.0645)
  Recall: 0.9333 (+/- 0.0972)
  F1: 0.9396 (+/- 0.0765)
  Roc_auc: 0.9333 (+/- 0.0972)
BCE Loss: 0.31
AU-ROC: 1.00
AU-PRC: 1.00
AU-PRC Baaseline: 0.68
Accuracy: 0.96
Precision: 0.95
Recall: 1.00
Specificity: 0.89
NPV: 1.00
ECE: 0.11
MCE: 0.58
Model saved to D:/ICUDATASET/data/output/Xgboost_model.pkl
=================== 3 FOLD=====================
train_hids 112
X_df (112, 1683)
y_df (112,)
test_hids 28
X_df (28, 1683)
y_df (28,)
Training shape: (112, 1683), Test shape: (28, 1683)
Training dtypes: {dtype('int64'): 1475, dtype('float64'): 208}
===============MODEL TRAINING===============
Fitting 5 folds for each of 32 candidates, totalling 160 fits
Best params for F1: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 1.0}
Best F1 score: 0.9772
Average CV Metrics:
  Accuracy: 0.9727 (+/- 0.0223)
  Precision: 0.9560 (+/- 0.0359)
  Recall: 1.0000 (+/- 0.0000)
  F1: 0.9772 (+/- 0.0187)
  Roc_auc: 0.9882 (+/- 0.0146)
BCE Loss: 0.17
AU-ROC: 1.00
AU-PRC: 1.00
AU-PRC Baaseline: 0.46
Accuracy: 1.00
Precision: 1.00
Recall: 1.00
Specificity: 1.00
NPV: 1.00
ECE: 0.08
MCE: 0.32
Model saved to D:/ICUDATASET/data/output/Xgboost_model.pkl
=================== 4 FOLD=====================
train_hids 112
X_df (112, 1683)
y_df (112,)
test_hids 28
X_df (28, 1683)
y_df (28,)
Training shape: (112, 1683), Test shape: (28, 1683)
Training dtypes: {dtype('int64'): 1475, dtype('float64'): 208}
===============MODEL TRAINING===============
Fitting 5 folds for each of 32 candidates, totalling 160 fits
Best params for F1: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}
Best F1 score: 0.9759
Average CV Metrics:
  Accuracy: 0.9731 (+/- 0.0220)
  Precision: 0.9703 (+/- 0.0364)
  Recall: 0.9833 (+/- 0.0333)
  F1: 0.9759 (+/- 0.0198)
  Roc_auc: 0.9674 (+/- 0.0289)
BCE Loss: 0.47
AU-ROC: 0.98
AU-PRC: 0.99
AU-PRC Baaseline: 0.54
Accuracy: 0.86
Precision: 0.92
Recall: 0.80
Specificity: 0.92
NPV: 0.80
ECE: 0.17
MCE: 0.76
Model saved to D:/ICUDATASET/data/output/Xgboost_model.pkl
=================== 5 FOLD=====================
train_hids 140
X_df (140, 1683)
y_df (140,)
test_hids 28
X_df (28, 1683)
y_df (28,)
Training shape: (140, 1683), Test shape: (28, 1683)
Training dtypes: {dtype('int64'): 1475, dtype('float64'): 208}
===============MODEL TRAINING===============
Fitting 5 folds for each of 32 candidates, totalling 160 fits
Best params for F1: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}
Best F1 score: 0.9810
Average CV Metrics:
  Accuracy: 0.9786 (+/- 0.0175)
  Precision: 0.9632 (+/- 0.0300)
  Recall: 1.0000 (+/- 0.0000)
  F1: 0.9810 (+/- 0.0155)
  Roc_auc: 0.9938 (+/- 0.0076)
BCE Loss: 0.14
AU-ROC: 1.00
AU-PRC: 1.00
AU-PRC Baaseline: 0.29
Accuracy: 1.00
Precision: 1.00
Recall: 1.00
Specificity: 1.00
NPV: 1.00
ECE: 0.07
MCE: 0.35
Model saved to D:/ICUDATASET/data/output/Xgboost_model.pkl
=================== 6 FOLD=====================
train_hids 140
X_df (140, 1683)
y_df (140,)
test_hids 28
X_df (28, 1683)
y_df (28,)
Training shape: (140, 1683), Test shape: (28, 1683)
Training dtypes: {dtype('int64'): 1475, dtype('float64'): 208}
===============MODEL TRAINING===============
Fitting 5 folds for each of 32 candidates, totalling 160 fits
Best params for F1: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}
Best F1 score: 0.9810
Average CV Metrics:
  Accuracy: 0.9786 (+/- 0.0175)
  Precision: 0.9632 (+/- 0.0300)
  Recall: 1.0000 (+/- 0.0000)
  F1: 0.9810 (+/- 0.0155)
  Roc_auc: 0.9938 (+/- 0.0076)
BCE Loss: 0.89
AU-ROC: 0.89
AU-PRC: 0.86
AU-PRC Baaseline: 0.54
Accuracy: 0.86
Precision: 0.79
Recall: 1.00
Specificity: 0.69
NPV: 1.00
ECE: 0.13
MCE: 0.81
Model saved to D:/ICUDATASET/data/output/Xgboost_model.pkl
=================== 7 FOLD=====================
train_hids 140
X_df (140, 1683)
y_df (140,)
test_hids 28
X_df (28, 1683)
y_df (28,)
Training shape: (140, 1683), Test shape: (28, 1683)
Training dtypes: {dtype('int64'): 1475, dtype('float64'): 208}
===============MODEL TRAINING===============
Fitting 5 folds for each of 32 candidates, totalling 160 fits
Best params for F1: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}
Best F1 score: 0.9810
Average CV Metrics:
  Accuracy: 0.9786 (+/- 0.0175)
  Precision: 0.9632 (+/- 0.0300)
  Recall: 1.0000 (+/- 0.0000)
  F1: 0.9810 (+/- 0.0155)
  Roc_auc: 0.9938 (+/- 0.0076)
BCE Loss: 0.17
AU-ROC: 1.00
AU-PRC: 1.00
AU-PRC Baaseline: 0.46
Accuracy: 0.96
Precision: 0.93
Recall: 1.00
Specificity: 0.93
NPV: 1.00
ECE: 0.06
MCE: 0.75
Model saved to D:/ICUDATASET/data/output/Xgboost_model.pkl
=================== 8 FOLD=====================
train_hids 140
X_df (140, 1683)
y_df (140,)
test_hids 28
X_df (28, 1683)
y_df (28,)
Training shape: (140, 1683), Test shape: (28, 1683)
Training dtypes: {dtype('int64'): 1475, dtype('float64'): 208}
===============MODEL TRAINING===============
Fitting 5 folds for each of 32 candidates, totalling 160 fits
Best params for F1: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}
Best F1 score: 0.9810
Average CV Metrics:
  Accuracy: 0.9786 (+/- 0.0175)
  Precision: 0.9632 (+/- 0.0300)
  Recall: 1.0000 (+/- 0.0000)
  F1: 0.9810 (+/- 0.0155)
  Roc_auc: 0.9938 (+/- 0.0076)
BCE Loss: 0.44
AU-ROC: 0.93
AU-PRC: 0.89
AU-PRC Baaseline: 0.54
Accuracy: 0.96
Precision: 0.94
Recall: 1.00
Specificity: 0.92
NPV: 1.00
ECE: 0.04
MCE: 0.15
Model saved to D:/ICUDATASET/data/output/Xgboost_model.pkl
=================== 9 FOLD=====================
train_hids 140
X_df (140, 1683)
y_df (140,)
test_hids 28
X_df (28, 1683)
y_df (28,)
Training shape: (140, 1683), Test shape: (28, 1683)
Training dtypes: {dtype('int64'): 1475, dtype('float64'): 208}
===============MODEL TRAINING===============
Fitting 5 folds for each of 32 candidates, totalling 160 fits
Best params for F1: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}
Best F1 score: 0.9810
Average CV Metrics:
  Accuracy: 0.9786 (+/- 0.0175)
  Precision: 0.9632 (+/- 0.0300)
  Recall: 1.0000 (+/- 0.0000)
  F1: 0.9810 (+/- 0.0155)
  Roc_auc: 0.9938 (+/- 0.0076)
BCE Loss: 0.56
AU-ROC: 0.99
AU-PRC: 0.99
AU-PRC Baaseline: 0.43
Accuracy: 0.89
Precision: 0.80
Recall: 1.00
Specificity: 0.81
NPV: 1.00
ECE: 0.13
MCE: 0.70
Model saved to D:/ICUDATASET/data/output/Xgboost_model.pkl
